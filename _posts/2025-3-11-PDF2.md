---
title:  "随机变量的运算II：矩母函数与特征函数"
mathjax: true
layout: post
categories: media
---

[前一篇文章](https://callofximeng.github.io/PDF/)通过概率的直接定义，计算了不同独立随机分布在进行运算之后得到新随机分布的PDF。然而，对于某些复杂的分布，积分其实是很难做的（~~物理学家只会做高斯积分~~）。另外，有时候我们只关心新分布的统计学性质，例如$N$阶中心矩，不是太关心它的PDF长什么样。有没有办法直接计算呢？还是拿两个随机分布的乘积举例，例如两个独立的高斯分布，其乘积的均值显然为0,即

$$\left< \mathcal{N} _1\mathcal{N} _2 \right> =0  $$

而乘积的方差

$$\left< \left( \mathcal{N} _1\mathcal{N} _2 \right) ^2 \right> =\left< {\mathcal{N} _1}^2 \right> \left< {\mathcal{N} _2}^2 \right> +2\left< \mathcal{N} _1\mathcal{N} _2 \right> ^2=\sigma _{1}^{2}\sigma _{2}^{2} $$

则为两个高斯分布方差之积。


然而，对于更一般的情况，这样的计算其实并不容易。幸运的是，我们仍然可以曲线救国，注意到一个随机分布的$N$阶段中心矩

$$\left< X^N \right> \equiv \int_{-\infty}^{\infty}{f_X\left( x \right) x^N\mathrm{d}x} $$

使用一个精妙的方法可以把这个$x^N$凑出来，例如，如果引入一个$\exp(tx)$，那么就有

$$ \frac{\partial^N}{\partial t^N} \exp(tx) = x^N\exp(tx). $$

$沿着这个思路，我们可以定义随机分布的矩母函数（moment generating function, MGF），即

$$ M_{X}(t)\equiv \left< \exp(tx) \right> = \int_{-\infty}^{\infty}{f_X\left( x \right) \exp(tx) \mathrm{d}x} $$

其实就是$f_X(-x)$的双边Laplace变换（注意到Laplace变换不总是存在的）。这样就很容易看出，$X$的$N$阶中心矩由$M_f(t)$在$t=0$处的$N$阶导给出，这也是为什么叫做母函数（生成函数）的原因。


由MGF定义，如果知道X的MGF,可以立即通过替换写出随机变量函数的MGF，例如

$$ M_{\alpha X+\beta}(t) =  \left< \exp\{t(\alpha x+\beta)\} \right> = \exp(\beta t) M_X(\alpha t) $$

再举一个非常有意思的例子，两个泊松分布相加仍然是泊松分布，但两个泊松分布相减，就会覆盖整个实数域$x\in\mathbb{R}$，显然不是泊松分布了。注意到泊松分布的MGF

$$ f\left( x \right) =\frac{\mathrm{e}^{-\lambda}\lambda ^x}{x!},\quad M_X\left( t \right) =\sum_{i=0}^{\infty}{\frac{\mathrm{e}^{tx-\lambda}\lambda ^x}{x!}}=\mathrm{e}^{\lambda \left( e^t-1 \right)} $$

那么两个泊松分布相减，由指数性质，得到的MGF由乘积给出

$$ M_{X_1-X_2}(t) = M_{X1}(t)M_{X_2}(-t) = \exp \left\{ \lambda _1\left( \mathrm{e}^t-1 \right) +\lambda _2\left( \mathrm{e}^{-t}-1 \right) \right\} $$

立即得到$\left<X_1-X_2\right>=\lambda_1-\lambda_2$，$\left<(X_1-X_2)^2\right>=\lambda_1+\lambda_2+(\lambda_1-\lambda_2)^2$，从而方差为$\sigma_{X_1-X_2}^2=\lambda_1+\lambda_2$。这时候我们其实完全不知道$X_1-X_2$满足什么样的分布。当然这个还是能查表或者让MMA算出来的，叫做Skellam分布，记为$\mathcal{K}(\lambda_1,\lambda_2)$，其PDF为

$$ f_{X_1-X_2}\left( z \right) =\mathrm{e}^{-\left( \lambda _1+\lambda _2 \right)}\left( \frac{\lambda _1}{\lambda _2} \right) ^{z/2}I_z\left( 2\sqrt{\lambda _1\lambda _2} \right)  $$

其中$I_z$为第一类修正Bessel函数。这个分布是专门拿来定义两个独立Poisson分布差的，直到Poisson作古106年后的1946年才被英国统计学家、经济学家Skellam推导出来。首先不提这个PDF有多复杂，直接做无穷级数求和就是极其浪费时间的事情。查表，发现均值以及方差确实和MGF算出来的一模一样，表明MGF非常好用。再看一个例子，两个独立的正态分布乘积，注意到，由定义

$$ M_{X\cdot Y}\left( t \right) =\iint{f_X\left( x \right) g_Y\left( y \right) \mathrm{e}^{txy}\mathrm{d}x\mathrm{d}y}=\int{M_X\left( ty \right) g_Y\left( y \right) \mathrm{d}y} $$

所以两个独立正态分布乘积的MGF为

$$ M_{X\cdot Y}\left( t \right) =\int_{-\infty}^{\infty}{\mathrm{e}^{\frac{1}{2}\sigma _{1}^{2}t^2y^2}\frac{1}{\sqrt{2\pi \sigma _{2}^{2}}}\mathrm{e}^{-\frac{1}{2}\frac{y^2}{\sigma _{2}^{2}}}}\mathrm{d}y=\frac{1}{\sqrt{1-\sigma _{1}^{2}\sigma _{2}^{2}t^2}} $$

立即得到期望$\left<X\cdot Y\right>=0$，方差$\left<(X\cdot Y)^2\right>=\sigma_1^2\sigma_2^2$，后者不难看出

$$ \left< \left( XY \right) ^2 \right> =\left< X^2 \right> \left< Y^2 \right> +2\left< XY \right> ^2=\sigma _{1}^{2}\sigma _{2}^{2} $$

有了MGF,怎样回到PDF呢？一个直接的想法是，再给它做逆拉普拉斯变换，变回去。即，

$$ f_X(x) = \frav{1}{2\pi} \int_{-\infty}^\infty M_{X}(t) \exp(-tx) \mathrm{d} t$$

观察积分形式，做变量替换$u\equiv\sigma_1\sigma_2 t$，以及$\cos\theta\equiv u$，[不难得到](https://dlmf.nist.gov/10.32)分布的PDF为

$$ h_Z(z)=\frac{1}{\sigma_1\sigma_2}K_0(\frac{\left|z\right|}{\sigma_1\sigma_2}) $$

这是一个Variance-Gamma分布 $VG(1/2,1/(\sigma_1\sigma_2),0,0)$，和[前一篇文章](https://callofximeng.github.io/PDF/)的结果一致。


然而，对MGF的积分不总是能实轴上完成，有时候可能需要Wick转动到虚轴附近，非常麻烦。于是有一个更加方便的做法，就是在计算MGF的时候，就直接做Fourier（逆）变换，得到特征函数（characteristic function, CF），即

$$ C_X\left( k \right) \equiv \int_{-\infty}^{\infty}{f_X\left( x \right) \mathrm{e}^{\mathrm{i}kx}}\mathrm{d}x,  f_X\left( x \right) \equiv \frac{1}{2\pi}\int_{-\infty}^{\infty}{C_X\left( k \right) \mathrm{e}^{-\mathrm{i}kx}}\mathrm{d}k $$

CF的性质和MGF差不多，求中心矩的时候需要额外考虑i$^N$。


作为总结，MGF以及CF最大的优势是在不计算具体PDF的情况下,就可以得到随机分布的各阶中心矩，还可以用来计算无关随机分布相互运算得到新随机分布的PDF,反正数值积分总是可以做的。
